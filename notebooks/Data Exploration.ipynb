{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc5583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext kedro.extras.extensions.ipython\n",
    "# %reload_kedro /home/ubuntu/dmc_2014/dmcfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c33600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "257ec1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-08 18:12:16,109 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...\n",
      "2022-03-08 18:12:16,110 - kedro.io.data_catalog - INFO - Loading data from `orders_train` (CSVDataSet)...\n",
      "2022-03-08 18:12:16,731 - kedro.io.data_catalog - INFO - Loading data from `orders_test` (CSVDataSet)...\n",
      "2022-03-08 18:12:16,788 - kedro.io.data_catalog - INFO - Loading data from `orders_test_y` (CSVDataSet)...\n",
      "2022-03-08 18:12:16,795 - kedro.io.data_catalog - INFO - Loading data from `orders_full` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "parameters = catalog.load(\"parameters\")\n",
    "# del orders\n",
    "orders_train = catalog.load(\"orders_train\")\n",
    "orders_test = catalog.load(\"orders_test\")\n",
    "orders_test_y = catalog.load(\"orders_test_y\")\n",
    "\n",
    "orders_full = catalog.load(\"orders_full\")\n",
    "\n",
    "orders_test[\"returnShipment\"] = orders_test_y[\"returnShipment\"]\n",
    "orders = pd.concat([orders_train, orders_test])\n",
    "orders[\"val_set\"] = 1\n",
    "orders.iloc[:len(orders_train), -1] = 0\n",
    "orders.drop(columns = [\"orderItemID\"], inplace = True)\n",
    "orders.replace(\"?\", np.nan, inplace = True)\n",
    "orders.reset_index(drop=True, inplace=True)\n",
    "orders.loc[:, \"color\"] = orders[\"color\"].str.replace(\"brwon\", \"brown\").str.replace(\"blau\",\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f4b07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_test[\"basketID\"] = orders_test[\"customerID\"].astype(str) + orders_test[\"deliveryDate\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6845edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  220474 received 131907 returns == PAPER Asdecker\n",
    "# orders_full[\"basketID\"] = orders_full[\"customerID\"].astype(str) + orders_full[\"deliveryDate\"].astype(str)\n",
    "# orders_full.drop(orders_full[orders_full[\"deliveryDate\"].isna()].index).groupby(\"basketID\")[\"returnShipment\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91af19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = orders_full.groupby([\"customerID\", \"orderDate\"])[\"deliveryDate\"].unique().reset_index()\n",
    "orders_dropped = orders_full.drop(orders_full[orders_full[\"deliveryDate\"].isna()].index)\n",
    "less_orders = orders_test.drop(orders_test[orders_test[\"deliveryDate\"]==\"?\"].index)\n",
    "59/147 # single item ret_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa843f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13107"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13.166 / 22.069\n",
    "# 13.107 / 21.922 -> when dropping delivery dates=na\n",
    "(less_orders.groupby(\"basketID\")[\"returnShipment\"].sum()>=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30038871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# less_orders.groupby(\"basketID\")[\"returnShipment\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cc78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = orders[orders[\"val_set\"]==0]\n",
    "test = orders[orders[\"val_set\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616803ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train[\"manufacturerID\"].value_counts().cumsum()/train.shape[0]).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943b88a",
   "metadata": {},
   "source": [
    "## Columns\n",
    "* nas in deliveryDate (39419), color (143), dateOfBirth (48889) all max ~10%\n",
    "    * dateOfBirth: impute\n",
    "    * delivery: impute (+maybe sundaycorrect)\n",
    "        * check for errors (delivery before order)\n",
    "    * color: drop\n",
    "* price: something with sale?\n",
    "    * watchout: multi-orders (e.g. 2 articles)\n",
    "    * check occurances of +50% sale: is it less often?\n",
    "* color: CAT (MAX OHE) oder CATBOOST\n",
    "* size: CAT\n",
    "    * problem: different sizes (M vs. 50) per type of clothes\n",
    "        * maybe adapt all to small letters + keep rest\n",
    "* manufacturer: catboost (?)\n",
    "* itemID\n",
    "    * basket (unten) + catboost\n",
    "* customer_id*orderDate = Bestnr\n",
    "    * joint ret_pct\n",
    "    * basket price\n",
    "    \n",
    "* Time columns: orderDate, deliveryDate, creationDate, dateOfBirth\n",
    "    * orderDate-deliveryDate: time for delivery\n",
    "        * use days to determine weekends\n",
    "    * orderDate: no_orders_day\n",
    "        * use it -> no\n",
    "    * age -> dateOfBirth-orderDate\n",
    "    \n",
    "    \n",
    "### OHE vs. algorithmic (Catboost)\n",
    "* OHE vs. own catboosted -> let's see what performs better\n",
    "* size\n",
    "    * use rel number of times item got bought\n",
    "* color\n",
    "    * same\n",
    "* possibility: use size+color combination\n",
    "#### A) all rel_numbers + av combinations B) rel number size + color B) OHE size+ color, rel number mixed C) only OHE D) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486164b",
   "metadata": {},
   "source": [
    "## Time columns >>Finished\n",
    "Features to create - 1st na the \"?\"\n",
    "* bugfixes for dateOfBirth, deliveryDate\n",
    "    * creation date: bc of system a lot on 2011-02-16 -> upgrade infrastructure etc.\n",
    "* day features\n",
    "    * order and day received\n",
    "    * adjust for sundays\n",
    "* delivery time [maybe (-1 for sundays)]\n",
    "* account age = time_creation - day_born\n",
    "    * maybe binning -> oldest category for acc\n",
    "* age at order = time order - day born"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75ebf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct typo\n",
    "orders.loc[orders[orders[\"dateOfBirth\"]==\"1655-04-19\"].index, \"dateOfBirth\"]= \"1955-04-19\"\n",
    "# convert to daytime\n",
    "time_cols = [\"orderDate\", \"deliveryDate\", \"creationDate\", \"dateOfBirth\"]\n",
    "for time_col in time_cols:\n",
    "    orders.loc[:, time_col] = pd.to_datetime(orders[time_col])\n",
    "    \n",
    "# correct senseless dates\n",
    "    # age: over ~100years or underaged (border year 2000)\n",
    "weird_age = orders[(orders[\"dateOfBirth\"].dt.year < 1915) & (orders[\"dateOfBirth\"].dt.year >= 2000)].index\n",
    "orders.loc[weird_age, \"dateOfBirth\"]= np.nan\n",
    "    # some bug with delivery_Date in 1990\n",
    "orders.loc[orders[orders[\"deliveryDate\"].dt.year == 1990].index, \"deliveryDate\"]= np.nan\n",
    "    # set same day deliveries to na\n",
    "same_day_inc = orders[orders[\"orderDate\"]==orders[\"deliveryDate\"]].index\n",
    "orders.loc[same_day_inc ,\"deliveryDate\"]= np.nan\n",
    "    # set day received to median time needed\n",
    "delivery_median = ((orders[\"deliveryDate\"]-orders[\"orderDate\"]).dt.days).median()\n",
    "delivery_nas = orders[orders[\"deliveryDate\"].isna()].index\n",
    "orders.loc[delivery_nas, \"deliveryDate\"] = orders.loc[\n",
    "    delivery_nas, \"orderDate\"] + pd.DateOffset(days = round(delivery_median))\n",
    "# adjust for sundays (no deliveries)\n",
    "sundays_inc = orders[orders[\"deliveryDate\"].dt.weekday==6].index\n",
    "orders.loc[sundays_inc, \"deliveryDate\"] = orders.loc[\n",
    "    sundays_inc, \"orderDate\"] + pd.DateOffset(days = 1)\n",
    "\n",
    "# create dict for features\n",
    "feature_cols_time = {}\n",
    "\n",
    "# create day features\n",
    "feature_cols_time[\"DAY_ORDER\"] = orders[\"orderDate\"].dt.dayofweek\n",
    "feature_cols_time[\"DAY_RECEIVED\"] = orders[\"deliveryDate\"].dt.dayofweek\n",
    "\n",
    "feature_cols_time[\"TIME_DELIVERY\"] = (orders[\"deliveryDate\"]-orders[\"orderDate\"]).dt.days\n",
    "we_del_ind = feature_cols_time[\"DAY_ORDER\"][\n",
    "    (feature_cols_time[\"DAY_ORDER\"]>feature_cols_time[\"DAY_RECEIVED\"])&\n",
    "    (feature_cols_time[\"DAY_ORDER\"] != 6)].index\n",
    "feature_cols_time[\"WE_DELIVERY\"] = pd.Series(data=0, index = orders.index)\n",
    "feature_cols_time[\"WE_DELIVERY\"].loc[we_del_ind] = 1 # package not late for those: ppl used to it\n",
    "feature_cols_time[\"USER_AGE_ORDER\"] = round((orders[\"orderDate\"]-orders[\"dateOfBirth\"]).dt.days/365)\n",
    "\n",
    "# binary == 1 if account was made on oldest date -> system import\n",
    "old_sys_inc = orders[\"creationDate\"][orders[\"creationDate\"]==min(orders[\"creationDate\"])].index\n",
    "feature_cols_time[\"ACC_OLD_SYS\"] = pd.Series(data=0, index = orders.index)\n",
    "feature_cols_time[\"ACC_OLD_SYS\"].loc[old_sys_inc] = 1\n",
    "# ~140 freshly made for order\n",
    "feature_cols_time[\"ACC_AGE_ORDER\"] = (orders[\"orderDate\"]-orders[\"creationDate\"]).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29605c8",
   "metadata": {},
   "source": [
    "### Prices and offers\n",
    "* some prices == 0, lower return pct (<10%)\n",
    "    * items do usually not always have price = 0\n",
    "        * \n",
    "    * does not seem like mistake etc.\n",
    "    * most customers just bought the article with price=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b98a9",
   "metadata": {},
   "source": [
    "* prices = 0 (1993 transactions)\n",
    "    * seems like no flaws in data -> keep\n",
    "* 21 arts (1084 transactions) with items priced always zero\n",
    "* 20 arts with mixed prices\n",
    "    * these items have a total of 6653 transactions (909==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf54ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles not in train df (new)\n",
    "test[~test[\"itemID\"].isin(train[\"itemID\"])].groupby(\"itemID\")[\"price\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e602785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993 7737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_price_arts = orders[orders[\"price\"]==0][\"itemID\"].unique()\n",
    "print(orders[orders[\"price\"]==0].shape[0], orders[orders[\"itemID\"].isin(no_price_arts)].shape[0])\n",
    "len(no_price_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c48c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_0_priced_items_incl = orders[orders[\"itemID\"].isin(no_price_arts)]\n",
    "nonlinear_arts = orders_0_priced_items_incl[orders_0_priced_items_incl[\"price\"]!=0][\"itemID\"].unique()\n",
    "len(nonlinear_arts) # items with 100pct discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e65a290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_0_arts = orders_0_priced_items_incl[~orders_0_priced_items_incl[\"itemID\"].isin(nonlinear_arts)][\"itemID\"].unique()\n",
    "\n",
    "# arts with price always zero (22) - totaling to 1084 orders\n",
    "orders[orders[\"itemID\"].isin(only_0_arts)].shape[0]\n",
    "\n",
    "# need to get imputed afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb3ea8",
   "metadata": {},
   "source": [
    "* numbers of prices + arts + transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af1f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  prices with no_unique_arts  1230 total transactions:  153567\n",
      "2  prices with no_unique_arts  775 total transactions:  103070\n",
      "3  prices with no_unique_arts  614 total transactions:  132889\n",
      "4  prices with no_unique_arts  251 total transactions:  77550\n",
      "5  prices with no_unique_arts  90 total transactions:  31671\n",
      "6  prices with no_unique_arts  28 total transactions:  15762\n",
      "7  prices with no_unique_arts  11 total transactions:  8356\n",
      "8  prices with no_unique_arts  6 total transactions:  5889\n",
      "9  prices with no_unique_arts  1 total transactions:  1322\n",
      "10  prices with no_unique_arts  1 total transactions:  1081\n"
     ]
    }
   ],
   "source": [
    "no_prices = orders_train.groupby(\"itemID\")[\"price\"].nunique()\n",
    "for price in range(1, 11):\n",
    "    art_ind = no_prices[no_prices==price].index\n",
    "    print(price, \" prices with no_unique_arts \", orders_train.groupby(\"itemID\")[\"price\"].nunique().value_counts().loc[price]\n",
    "         , \"total transactions: \", orders[orders[\"itemID\"].isin(art_ind)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1d2272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quest_max_p = []\\nfor article in multi_price_arts:\\n    art_prices = orders[orders[\"itemID\"]==article][\"price\"]\\n    if max(art_prices) != art_prices.value_counts().index[0]:\\n        max_p = max(art_prices)\\n        occs = art_prices[art_prices==max_p].shape[0]\\n        print(article,max_p, occs , art_prices.value_counts().iloc[0], art_prices.value_counts().index[0])\\n        quest_max_p += [article]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_price_arts = no_prices.drop(no_prices[no_prices==1].index).index\n",
    "\"\"\"quest_max_p = []\n",
    "for article in multi_price_arts:\n",
    "    art_prices = orders[orders[\"itemID\"]==article][\"price\"]\n",
    "    if max(art_prices) != art_prices.value_counts().index[0]:\n",
    "        max_p = max(art_prices)\n",
    "        occs = art_prices[art_prices==max_p].shape[0]\n",
    "        print(article,max_p, occs , art_prices.value_counts().iloc[0], art_prices.value_counts().index[0])\n",
    "        quest_max_p += [article]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d115ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13543/3333265182.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  discount = 1- orders.apply(lambda x: x[\"price\"]/max_prices.loc[x[\"itemID\"]], axis = 1)\n"
     ]
    }
   ],
   "source": [
    "max_prices = orders.groupby(\"itemID\")[\"price\"].max()\n",
    "discount = 1- orders.apply(lambda x: x[\"price\"]/max_prices.loc[x[\"itemID\"]], axis = 1)\n",
    "discount.loc[discount[discount.isna()].index] = 1\n",
    "# isna for price=0 -> impute 1 as RABATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce91717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemID  orderDate \n",
       "1       2012-04-01    1\n",
       "        2012-04-02    1\n",
       "        2012-04-03    1\n",
       "        2012-04-04    1\n",
       "        2012-04-05    1\n",
       "                     ..\n",
       "3073    2013-04-26    1\n",
       "3075    2013-04-10    1\n",
       "3076    2013-04-12    1\n",
       "3077    2013-04-13    1\n",
       "3079    2013-04-19    1\n",
       "Name: price, Length: 171787, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prices differ for article combinations; sometimes even for same (color*itemID*)\n",
    "day_prices = orders.groupby([\"itemID\", \"orderDate\"])[\"price\"].nunique().reset_index()\n",
    "orders.groupby([\"itemID\", \"orderDate\"])[\"price\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80c998b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders[(orders[\"itemID\"]==1)&(orders[\"orderDate\"]==\"2012-06-28\")]\n",
    "# diff_priced = [articles+=  for article in multi_price_arts]\n",
    "stds_price = orders_train.groupby(\"itemID\")[\"price\"].std()\n",
    "# (orders_test.groupby(\"itemID\")[\"price\"].std()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09a72966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rabatt\n",
    "((orders_train.groupby(\"itemID\")[\"price\"].max() - orders_train.groupby(\"itemID\")[\"price\"].min()) / orders_train.groupby(\"itemID\")[\"price\"].max()).hist(bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d3f36",
   "metadata": {},
   "source": [
    "## CATBOOST\n",
    "* manufacturer + article number (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5dae36",
   "metadata": {},
   "source": [
    "### Sizes + Colors (clean) + OHE\n",
    "* clean: size -> upper + lowercase; color -> blau and brwn\n",
    "* use relative occurances and no_combinations (how often [%] article gets bought per size+color\n",
    "    * color\n",
    "    * size\n",
    "    * size+color\n",
    "* alternative: OHE\n",
    "* alternative: cat_size_color_boost --> generate sub-art categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc86bd2",
   "metadata": {},
   "source": [
    "#### relative occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ed4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l       73297\n",
       "xl      66798\n",
       "m       61787\n",
       "xxl     51431\n",
       "40      37504\n",
       "        ...  \n",
       "2932        2\n",
       "105         2\n",
       "110         1\n",
       "4232        1\n",
       "85          1\n",
       "Name: size, Length: 115, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.loc[:, \"size\"] = orders[\"size\"].str.lower()\n",
    "orders[\"size\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d008c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = orders[orders[\"val_set\"]==0]\n",
    "arts_occ = train.groupby([\"itemID\"]).size()\n",
    "rel_sizes = train.groupby([\"itemID\", \"size\"]).size().reset_index()\n",
    "rel_sizes[\"rel_occ\"] = rel_sizes.apply(lambda x: x[0]/arts_occ.loc[x[\"itemID\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64f80042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = orders.groupby([\"itemID\", \"size\"]).size().reset_index()\n",
    "no_sizes = orders.groupby([\"itemID\"])[\"size\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca8fc7",
   "metadata": {},
   "source": [
    "#### sub-categories (color+size catboosted)\n",
    "* if possible: use noise (esp for small no of occurances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afe8e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.438517618469014"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby([\"itemID\", \"color\"]).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ad05066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.164863639308155"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby([\"itemID\", \"size\"]).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4989940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.759144254278729"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wenige Einträge: Annahme -> eher Farbe oder Größe und nicht beides zusammen hat Einfluss\n",
    "train.groupby([\"itemID\", \"size\", \"color\"]).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c14198f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_color_cat = orders[\"itemID\"].astype(str)+\"_\"+orders[\"color\"]\n",
    "item_size_cat = orders[\"itemID\"].astype(str)+\"_\"+orders[\"size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efed473",
   "metadata": {},
   "source": [
    "## Orders (Basket)\n",
    "* basket price + n_arts + joint_ret_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "768a976a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4740835213708756"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders[\"basketID\"] = orders[\"customerID\"].astype(str) + orders[\"orderDate\"].astype(str)\n",
    "\n",
    "n_arts_lookup = orders[\"basketID\"].value_counts()\n",
    "basket_price_lookup = orders.groupby(\"basketID\")[\"price\"].sum()\n",
    "\n",
    "orders[\"basket_price\"] = pd.Series(data = basket_price_lookup.loc[orders[\"basketID\"]].values, index = orders.index)\n",
    "orders[\"basketNArts\"] =  pd.Series(data = n_arts_lookup.loc[orders[\"basketID\"]].values, index = orders.index)\n",
    "\n",
    "orders.groupby(\"basketID\").size().mean()\n",
    "# average 3.47 articles in basket\n",
    "# less than one percent has only one item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdb318f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49861583517443353"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orders with just one article get less often returned\n",
    "orders[orders[\"basketNArts\"]==1][\"returnShipment\"].mean()\n",
    "orders[orders[\"basketNArts\"]>1][\"returnShipment\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc15c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5235652934328342"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders[orders[[\"basketID\", \"itemID\"]].duplicated(keep=False)][\"returnShipment\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c82af",
   "metadata": {},
   "source": [
    "### plot for paper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "049fff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_sizes = (orders.groupby(\"basketID\").size().value_counts()*orders.groupby(\"basketID\").size().value_counts().index).sort_index()\n",
    "# basket_sizes.cumsum().plot()\n",
    "# plot no_articles per basket size\n",
    "# basket_sizes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f33b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = orders[orders[\"val_set\"]==0]\n",
    "ret_frame = train[train[\"basketID\"].duplicated(keep=False)]\n",
    "noret_frame = train[~train[\"basketID\"].duplicated(keep=False)]\n",
    "\n",
    "test = orders[orders[\"val_set\"]==1]\n",
    "ret_frame = test[test[\"basketID\"].duplicated(keep=False)]\n",
    "noret_frame = test[~test[\"basketID\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed648974",
   "metadata": {},
   "outputs": [],
   "source": [
    "noret_series = noret_frame.apply(lambda x: x[\"deliveryDate\"].month, axis = 1)\n",
    "ret_series = ret_frame.apply(lambda x: x[\"deliveryDate\"].month, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd762508",
   "metadata": {},
   "outputs": [],
   "source": [
    "examp = {\"first\": ret_series,\n",
    "        \"second\": noret_series}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fa65a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "examp2 = {\"first\": ret_series,\n",
    "        \"second\": noret_series}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f78d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col='returnShipment'\n",
    "ordnr_col='basketID'\n",
    "artnr_col='itemID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1784a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = orders\n",
    "df = data[data[\"val_set\"]==0]\n",
    "test_df = data[data[\"val_set\"]==1]\n",
    "\n",
    "# fit\n",
    "# mean_ret_op = data[parameters['return_type']].mean()\n",
    "multi_arts = df[df[ordnr_col].duplicated(keep=False)]\n",
    "multi_arts = multi_arts[[artnr_col, ordnr_col, ret_col]]\n",
    "\n",
    "ret_arts = multi_arts[multi_arts[ret_col]==1][artnr_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abf423f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to edit: use dicts; replace artikelnr\n",
    "\n",
    "def finalize_features(data, parameters: dict):\n",
    "    ret_col = parameters['ret_col'] # y\n",
    "    ordnr_col = parameters['ordnr_col'] # indicator\n",
    "    artnr_col = parameters['artnr_col'] # X (data)\n",
    "    \n",
    "    hyperparams = parameters['ret_p_hyperparams']\n",
    "    min_n_arts = hyperparams[\"min_joint_baskets\"]\n",
    "    top_fs = hyperparams[\"top_freq_arts\"]\n",
    "    weights = hyperparams[\"weights\"]\n",
    "    drop_double_rets = hyperparams[\"drop_double_returns\"]\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    # feature generation: cut predictions before \n",
    "    df = data[data[\"val_set\"]==0]\n",
    "    test_df = data[data[\"val_set\"]==1]\n",
    "    \n",
    "    # fit\n",
    "    # mean_ret_op = data[parameters['return_type']].mean()\n",
    "    multi_arts = df[df[ordnr_col].duplicated(keep=False)]\n",
    "    multi_arts = multi_arts[[artnr_col, ordnr_col, ret_col]]\n",
    "\n",
    "    ret_arts = multi_arts[multi_arts[ret_col]==1][artnr_col].unique()\n",
    "    print(\"Bestellungen in Multi-Art-Warenkörben: \", multi_arts.shape[0], \" von \", df.shape[0])\n",
    "    print(\"Number of in Multi-Arts-Baskets that got returned \", multi_arts[artnr_col].isin(ret_arts).sum())\n",
    "    \n",
    "    ret_arts_frame = multi_arts[multi_arts[artnr_col].isin(ret_arts)]\n",
    "    lookup_ret_perc_art = ret_arts_frame.groupby(artnr_col)[ret_col].mean().to_dict()\n",
    "\n",
    "    lookup_tot_ord = multi_arts.groupby(artnr_col).size()\n",
    "    n_transactions = multi_arts.shape[0]\n",
    "    lookup_rel_ord = (lookup_tot_ord/n_transactions).to_dict()\n",
    "    \n",
    "    # generate empty nested dicts for every combination\n",
    "    lookup_lift_arts = {key: {} for key in min_n_arts}\n",
    "    lookup_basket_occ = {key: {} for key in min_n_arts}\n",
    "    lookup_basket_ret_p = {key: {} for key in min_n_arts}\n",
    "    lookup_droped_ret_arts = {key: [] for key in min_n_arts}\n",
    "    for article in ret_arts:\n",
    "        art_df = multi_arts[multi_arts[artnr_col]==article][[ordnr_col, ret_col]]\n",
    "        ret_orders = art_df[art_df[ret_col]>=1][ordnr_col]\n",
    "\n",
    "        basket_df = multi_arts[(multi_arts[ordnr_col].isin(art_df[ordnr_col])) &    # all articles which were ordered with article\n",
    "                      (multi_arts[artnr_col] != article)]\n",
    "        if drop_double_rets:   # ignores probability if both articles got returned\n",
    "            basket_df = basket_df.drop(basket_df[basket_df[ret_col]==1].index)\n",
    "        else:\n",
    "            basket_df.loc[:, ret_col] = 0   # set all ret_cols to 0\n",
    "        ret_incides = basket_df[basket_df[ordnr_col].isin(ret_orders)].index\n",
    "        basket_df.loc[ret_incides, ret_col] = 1 # set ret_col = 1 if returned\n",
    "        basket_grouped = basket_df.groupby(artnr_col).size()\n",
    "        \n",
    "        # for every min_joint_baseket combination\n",
    "        for n_arts in min_n_arts:\n",
    "            arts_basket_occ = basket_grouped[basket_grouped>=n_arts]   # only add arts with sufficient occurances\n",
    "            if arts_basket_occ.shape[0] > 0:\n",
    "                lookup_basket_occ[n_arts][article] = arts_basket_occ   # .to_dict() # minimum of co-occurances\n",
    "                lookup_basket_ret_p[n_arts][article] = basket_df[basket_df[artnr_col].isin(arts_basket_occ.keys())].groupby(\n",
    "                    artnr_col)[ret_col].mean()  #.to_dict()\n",
    "                lookup_lift_arts[n_arts][article] = arts_basket_occ.index.to_series().apply(lambda x: (arts_basket_occ.loc[x]/n_transactions)/\n",
    "                                      (lookup_rel_ord[article]*lookup_rel_ord[x]))\n",
    "            else:\n",
    "                lookup_droped_ret_arts[n_arts] += [article]\n",
    "    \n",
    "    used_cols = [artnr_col, ordnr_col, ret_col]\n",
    "    arts_used_ret_p = {}\n",
    "    arts_ret_p = {}\n",
    "    for n_arts in min_n_arts:\n",
    "        for top_f in top_fs:\n",
    "            for weight in weights:\n",
    "                colname = \"min_\"+str(n_arts)+\"_top_\"+str(top_f)+ \"_\"+str(weight) + \"_\"\n",
    "                data[colname+\"_lift\"] = np.nan\n",
    "                data[colname+\"_conf\"] = np.nan\n",
    "                # create df for test and train data\n",
    "                subframe_train = df[df[artnr_col].isin(lookup_basket_ret_p[n_arts].keys()) & # article got returned (+ has at least min_joint_basket occurances)\n",
    "                        (df[ordnr_col].duplicated(keep=False))][used_cols]    # includes ret_col for train_data to regularize own influence\n",
    "                subframe_test = test_df[test_df[artnr_col].isin(lookup_basket_ret_p[n_arts].keys()) & # article got returned (+ has at least min_joint_basket occurances)\n",
    "                        (test_df[ordnr_col].duplicated(keep=False))][[artnr_col, ordnr_col]]\n",
    "                \n",
    "                # apply function for lift and confidence to training data\n",
    "                ret_pcts_conf_train = subframe_train.apply(lambda x: get_ret_perc_train(\n",
    "                    x[1], x[2], df[used_cols], lookup_basket_ret_p[n_arts][(x[0])], lookup_basket_occ[n_arts][(x[0])],\n",
    "                    lookup_basket_occ[n_arts][(x[0])], top_f, weight), axis=1, result_type='expand')\n",
    "                ret_pcts_lift_train = subframe_train.apply(lambda x: get_ret_perc_train(\n",
    "                    x[1], x[2], df[used_cols], lookup_basket_ret_p[n_arts][(x[0])], lookup_basket_occ[n_arts][(x[0])],\n",
    "                    lookup_lift_arts[n_arts][(x[0])], top_f, weight), axis=1, result_type='expand')\n",
    "\n",
    "                # apply function for lift and confidence to test data\n",
    "                ret_pcts_conf_test = subframe_test.apply(lambda x: get_ret_perc_test(\n",
    "                    x[1], test_df[used_cols], lookup_basket_ret_p[n_arts][(x[0])], lookup_basket_occ[n_arts][(x[0])],\n",
    "                    lookup_basket_occ[n_arts][(x[0])], top_f, weight), axis=1, result_type='expand')\n",
    "                ret_pcts_lift_test = subframe_test.apply(lambda x: get_ret_perc_test(\n",
    "                    x[1], test_df[used_cols], lookup_basket_ret_p[n_arts][(x[0])], lookup_basket_occ[n_arts][(x[0])],\n",
    "                    lookup_lift_arts[n_arts][(x[0])], top_f, weight), axis=1, result_type='expand')\n",
    "                print(ret_pcts_lift_train.iloc[:, 0].head(), ret_pcts_conf_train.iloc[:, 0].head())\n",
    "                \n",
    "                arts_used_ret_p[colname+\"lift\"] = pd.concat([ret_pcts_lift_train.iloc[:, 1],\n",
    "                                                             ret_pcts_lift_test.iloc[:, 1]])\n",
    "                arts_used_ret_p[colname+\"conf\"] = pd.concat([ret_pcts_conf_train.iloc[:, 1],\n",
    "                                                              ret_pcts_conf_test.iloc[:, 1]])\n",
    "                \n",
    "                arts_ret_p[colname+\"lift\"] = pd.concat([ret_pcts_lift_train.iloc[:, 0],\n",
    "                                                             ret_pcts_lift_test.iloc[:, 0]])\n",
    "                arts_ret_p[colname+\"conf\"] = pd.concat([ret_pcts_conf_train.iloc[:, 0],\n",
    "                                                              ret_pcts_conf_test.iloc[:, 0]])\n",
    "        print(colname, \"subframe_train:\", subframe_train.shape[0], \" subframe_test:\", subframe_test.shape[0])\n",
    "                \n",
    "    return [arts_ret_p, lookup_basket_occ, lookup_basket_ret_p, lookup_ret_perc_art, \n",
    "            lookup_tot_ord, lookup_lift_arts, lookup_droped_ret_arts, arts_used_ret_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a85c7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_arts_frame = multi_arts[multi_arts[artnr_col].isin(ret_arts)]\n",
    "lookup_ret_perc_art = ret_arts_frame.groupby(artnr_col)[ret_col].mean().to_dict()\n",
    "\n",
    "lookup_tot_ord = multi_arts.groupby(artnr_col).size()\n",
    "n_transactions = multi_arts.shape[0]\n",
    "lookup_rel_ord = (lookup_tot_ord/n_transactions).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dacab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = train[(train[\"returnShipment\"]==1)&\n",
    "      ((train[\"basketNArts\"]>1))][\"itemID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77e6c37f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basket_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m multi_arts \u001b[38;5;241m=\u001b[39m train[train[ordnr_col]\u001b[38;5;241m.\u001b[39mduplicated(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m      2\u001b[0m ret_arts \u001b[38;5;241m=\u001b[39m multi_arts[multi_arts[ret_col]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m][artnr_col]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m----> 4\u001b[0m basket_grouped \u001b[38;5;241m=\u001b[39m \u001b[43mbasket_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(artnr_col)\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'basket_df' is not defined"
     ]
    }
   ],
   "source": [
    "multi_arts = train[train[ordnr_col].duplicated(keep=False)]\n",
    "ret_arts = multi_arts[multi_arts[ret_col]==1][artnr_col].unique()\n",
    "\n",
    "# basket_grouped = basket_df.groupby(artnr_col).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf18651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 10:41:20,183 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...\n",
      "2022-02-07 10:41:20,184 - kedro.io.data_catalog - INFO - Loading data from `orders_train` (CSVDataSet)...\n",
      "2022-02-07 10:41:20,771 - kedro.io.data_catalog - INFO - Loading data from `orders_test` (CSVDataSet)...\n",
      "2022-02-07 10:41:20,828 - kedro.io.data_catalog - INFO - Loading data from `orders_test_y` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "parameters = catalog.load(\"parameters\")\n",
    "# del orders\n",
    "orders_train = catalog.load(\"orders_train\")\n",
    "orders_test = catalog.load(\"orders_test\")\n",
    "orders_test_y = catalog.load(\"orders_test_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d780d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_test[\"returnShipment\"] = orders_test_y[\"returnShipment\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "176f8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderDate</th>\n",
       "      <th>deliveryDate</th>\n",
       "      <th>itemID</th>\n",
       "      <th>size</th>\n",
       "      <th>color</th>\n",
       "      <th>manufacturerID</th>\n",
       "      <th>price</th>\n",
       "      <th>customerID</th>\n",
       "      <th>salutation</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>state</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>returnShipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>2012-04-03</td>\n",
       "      <td>186</td>\n",
       "      <td>m</td>\n",
       "      <td>denim</td>\n",
       "      <td>25</td>\n",
       "      <td>69.90</td>\n",
       "      <td>794</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1965-01-06</td>\n",
       "      <td>Baden-Wuerttemberg</td>\n",
       "      <td>2011-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>2012-04-03</td>\n",
       "      <td>71</td>\n",
       "      <td>9+</td>\n",
       "      <td>ocher</td>\n",
       "      <td>21</td>\n",
       "      <td>69.95</td>\n",
       "      <td>794</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1965-01-06</td>\n",
       "      <td>Baden-Wuerttemberg</td>\n",
       "      <td>2011-04-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>2012-04-03</td>\n",
       "      <td>71</td>\n",
       "      <td>9+</td>\n",
       "      <td>curry</td>\n",
       "      <td>21</td>\n",
       "      <td>69.95</td>\n",
       "      <td>794</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1965-01-06</td>\n",
       "      <td>Baden-Wuerttemberg</td>\n",
       "      <td>2011-04-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>m</td>\n",
       "      <td>green</td>\n",
       "      <td>14</td>\n",
       "      <td>39.90</td>\n",
       "      <td>808</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1959-11-09</td>\n",
       "      <td>Saxony</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-02</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>151</td>\n",
       "      <td>39</td>\n",
       "      <td>black</td>\n",
       "      <td>53</td>\n",
       "      <td>29.90</td>\n",
       "      <td>825</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1964-07-11</td>\n",
       "      <td>Rhineland-Palatinate</td>\n",
       "      <td>2011-02-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50073</th>\n",
       "      <td>2013-04-29</td>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>2342</td>\n",
       "      <td>M</td>\n",
       "      <td>terracotta</td>\n",
       "      <td>5</td>\n",
       "      <td>69.90</td>\n",
       "      <td>91920</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1962-03-08</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>2013-04-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50074</th>\n",
       "      <td>2013-04-29</td>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>2505</td>\n",
       "      <td>M</td>\n",
       "      <td>terracotta</td>\n",
       "      <td>5</td>\n",
       "      <td>64.90</td>\n",
       "      <td>91920</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1962-03-08</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>2013-04-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50075</th>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2470</td>\n",
       "      <td>XL</td>\n",
       "      <td>white</td>\n",
       "      <td>5</td>\n",
       "      <td>79.90</td>\n",
       "      <td>85095</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1950-02-14</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2013-03-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50076</th>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2452</td>\n",
       "      <td>L</td>\n",
       "      <td>white</td>\n",
       "      <td>5</td>\n",
       "      <td>59.90</td>\n",
       "      <td>91922</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1969-11-27</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50077</th>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2452</td>\n",
       "      <td>L</td>\n",
       "      <td>black</td>\n",
       "      <td>5</td>\n",
       "      <td>59.90</td>\n",
       "      <td>91922</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1969-11-27</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>531170 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        orderDate deliveryDate  itemID size       color  manufacturerID  \\\n",
       "0      2012-04-01   2012-04-03     186    m       denim              25   \n",
       "1      2012-04-01   2012-04-03      71   9+       ocher              21   \n",
       "2      2012-04-01   2012-04-03      71   9+       curry              21   \n",
       "3      2012-04-02          NaN      22    m       green              14   \n",
       "4      2012-04-02   1990-12-31     151   39       black              53   \n",
       "...           ...          ...     ...  ...         ...             ...   \n",
       "50073  2013-04-29   2013-05-03    2342    M  terracotta               5   \n",
       "50074  2013-04-29   2013-05-03    2505    M  terracotta               5   \n",
       "50075  2013-04-28   2013-05-02    2470   XL       white               5   \n",
       "50076  2013-04-28          NaN    2452    L       white               5   \n",
       "50077  2013-04-28          NaN    2452    L       black               5   \n",
       "\n",
       "       price  customerID salutation dateOfBirth                 state  \\\n",
       "0      69.90         794        Mrs  1965-01-06    Baden-Wuerttemberg   \n",
       "1      69.95         794        Mrs  1965-01-06    Baden-Wuerttemberg   \n",
       "2      69.95         794        Mrs  1965-01-06    Baden-Wuerttemberg   \n",
       "3      39.90         808        Mrs  1959-11-09                Saxony   \n",
       "4      29.90         825        Mrs  1964-07-11  Rhineland-Palatinate   \n",
       "...      ...         ...        ...         ...                   ...   \n",
       "50073  69.90       91920        Mrs  1962-03-08               Bavaria   \n",
       "50074  64.90       91920        Mrs  1962-03-08               Bavaria   \n",
       "50075  79.90       85095        Mrs  1950-02-14                Berlin   \n",
       "50076  59.90       91922        Mrs  1969-11-27           Brandenburg   \n",
       "50077  59.90       91922        Mrs  1969-11-27           Brandenburg   \n",
       "\n",
       "      creationDate  returnShipment  \n",
       "0       2011-04-25               0  \n",
       "1       2011-04-25               1  \n",
       "2       2011-04-25               1  \n",
       "3       2012-01-04               0  \n",
       "4       2011-02-16               0  \n",
       "...            ...             ...  \n",
       "50073   2013-04-29               1  \n",
       "50074   2013-04-29               1  \n",
       "50075   2013-03-24               0  \n",
       "50076   2013-04-28               0  \n",
       "50077   2013-04-28               0  \n",
       "\n",
       "[531170 rows x 13 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.concat([orders_train, orders_test])\n",
    "combined.drop(columns = [\"orderItemID\"], inplace = True)\n",
    "combined.replace(\"?\", np.nan, inplace = True)\n",
    "# combined.drop(combined[\"color\"].isna().index, inplace = True)\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02582947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ret_perc_train(bestnr, ret_ind, data, ret_p_art, occ_arts, sort_arts, top_f, weights):\n",
    "    # sort arts: use df with lift if lift, else no_occurances\n",
    "    # function init: pick all articles from basket \n",
    "    basket_arts = data[(data.iloc[:, 1] == bestnr) &    # iloc[:,1] = Column ordernr\n",
    "             (data.iloc[:, 0].isin(ret_p_art.index))].iloc[:, 0]     # iloc[:,0] = Column article\n",
    "    if len(basket_arts)==0:\n",
    "        return np.nan, 0\n",
    "    else: \n",
    "        # sorting specified by series in input (from lookup_lift_arts or lookup_basket_occ)\n",
    "        sorted_arts = sort_arts.loc[basket_arts].sort_values().index.to_series()\n",
    "\n",
    "        if top_f:\n",
    "            if type(top_f) == str: # for values like var_5 -> variable 5 or if len(arts)>5 -> take half of the most frq\n",
    "                n_min = [int(s) for s in top_f if s.isdigit()][0]\n",
    "                top_f = max(n_min, round(len(sorted_arts)/2))\n",
    "            sorted_arts = sorted_arts.iloc[-top_f:]\n",
    "\n",
    "        # adapt for training data (fix ret_p) to prevent overfitting\n",
    "        ret_p_basket = ret_p_art.loc[sorted_arts]\n",
    "        occ_basket = occ_arts.loc[sorted_arts]\n",
    "        no_ret_ind = 1 - ret_ind\n",
    "        ret_p_basket = (ret_p_basket*occ_basket-ret_ind   # numerator = no returns of article\n",
    "                                )/(occ_basket-no_ret_ind)  # denominator = no orders of article\n",
    "\n",
    "        if weights: # if no weigths: only use mean of pcts\n",
    "            weight = range(1, sorted_arts.shape[0]+1)\n",
    "            if weights == \"sqrt_w\":\n",
    "                weight = np.sqrt(weight)\n",
    "            ret_pcts = (ret_p_basket*weight).sum()/sum(weight)\n",
    "        else:\n",
    "            ret_pcts = ret_p_basket.mean()\n",
    "\n",
    "        return ret_pcts, occ_basket.sum()\n",
    "\n",
    "def get_ret_perc_test(bestnr, data, ret_p_art, occ_arts, sort_arts, top_f, weights):\n",
    "    # function init: pick all articles from basket \n",
    "    basket_arts = data[(data.iloc[:, 1] == bestnr) &    # iloc[:,1] = Column ordernr\n",
    "             (data.iloc[:, 0].isin(ret_p_art.index))].iloc[:, 0]     # iloc[:,0] = Column article\n",
    "    if len(basket_arts)==0:\n",
    "        return np.nan, 0\n",
    "    else:\n",
    "        # sorting specified by series in input (from lookup_lift_arts or lookup_basket_occ)\n",
    "        sorted_arts = sort_arts.loc[basket_arts].sort_values().index.to_series()\n",
    "\n",
    "        if top_f:\n",
    "            if type(top_f) == str: # for values like var_5 -> variable 5 or if len(arts)>5 -> take half of the most frq\n",
    "                n_min = [int(s) for s in top_f if s.isdigit()][0]\n",
    "                top_f = max(n_min, round(len(sorted_arts)/2))\n",
    "            sorted_arts = sorted_arts.iloc[-top_f:]\n",
    "\n",
    "        if weights: # if no weigths: only use mean of pcts\n",
    "            weight = range(1, sorted_arts.shape[0]+1)\n",
    "            if weights == \"sqrt_w\": # middle parth for sorting importance-wise\n",
    "                weight = np.sqrt(weight)\n",
    "            ret_pcts = (ret_p_art.loc[sorted_arts]*weight).sum()/sum(weight)\n",
    "        else:\n",
    "            ret_pcts = ret_p_art.loc[sorted_arts].mean()\n",
    "\n",
    "        return ret_pcts, occ_arts.loc[sorted_arts].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = parameters['ret_p_hyperparams']\n",
    "min_n_arts = hyperparams[\"min_joint_baskets\"]\n",
    "top_fs = hyperparams[\"top_freq_arts\"]\n",
    "weights = hyperparams[\"weights\"]\n",
    "drop_double_rets = hyperparams[\"drop_double_returns\"]\n",
    "\n",
    "for n_arts in min_n_arts:\n",
    "    for top_f in top_fs:\n",
    "        for weight in weights:\n",
    "            print(\"min_\"+str(n_arts)+\"_top_\"+str(top_f)+ \"_\"+str(weight) + \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    cols_dict = parameters['cols_dict'] \n",
    "    data_cols = cols_dict['pass_cat_cols'] + cols_dict['enc_cat_cols'] + cols_dict['cont_cols'] + [parameters['return_type']] + ['BELEGDATUM'] # dates necessary for splits\n",
    "    data = data[data_cols]\n",
    "    print(data.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def finalize_features(data, parameters: dict):\n",
    "    ret_col = parameters['ret_col'] # y\n",
    "    ordnr_col = parameters['ordnr_col'] # indicator\n",
    "    artnr_col = parameters['artnr_col'] # X (data)\n",
    "    \n",
    "    hyperparams = parameters['ret_p_hyperparams']\n",
    "    min_n_arts = hyperparams[\"min_joint_baskets\"]\n",
    "    top_fs = hyperparams[\"top_freq_arts\"]\n",
    "    weights = hyperparams[\"weights\"]\n",
    "    drop_double_rets = hyperparams[\"drop_double_returns\"]\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    # feature generation: cut predictions before \n",
    "    df = data[data[\"val_set\"]==0]\n",
    "    test_df = data[data[\"val_set\"]==1]\n",
    "    \n",
    "    # fit\n",
    "    # mean_ret_op = data[parameters['return_type']].mean()\n",
    "    multi_arts = df[df[ordnr_col].duplicated(keep=False)]\n",
    "    multi_arts = multi_arts[[artnr_col, ordnr_col, ret_col]]\n",
    "\n",
    "    ret_arts = multi_arts[multi_arts[ret_col]==1][artnr_col].unique()\n",
    "    print(\"Bestellungen in Multi-Art-Warenkörben: \", multi_arts.shape[0], \" von \", df.shape[0])\n",
    "    print(\"Number of in Multi-Arts-Baskets that got returned \", multi_arts[artnr_col].isin(ret_arts).sum())\n",
    "    \n",
    "    ret_arts_frame = multi_arts[multi_arts[artnr_col].isin(ret_arts)]\n",
    "    lookup_ret_perc_art = ret_arts_frame.groupby(artnr_col)[ret_col].mean().to_dict()\n",
    "\n",
    "    lookup_tot_ord = multi_arts.groupby(artnr_col).size()\n",
    "    n_transactions = multi_arts.shape[0]\n",
    "    lookup_rel_ord = (lookup_tot_ord/n_transactions).to_dict()\n",
    "    \n",
    "    # generate empty nested dicts for every combination\n",
    "    lookup_lift_arts = {key: {} for key in min_n_arts}\n",
    "    lookup_basket_occ = {key: {} for key in min_n_arts}\n",
    "    lookup_basket_ret_p = {key: {} for key in min_n_arts}\n",
    "    lookup_droped_ret_arts = {key: [] for key in min_n_arts}\n",
    "    for article in ret_arts:\n",
    "        art_df = multi_arts[multi_arts[artnr_col]==article][[ordnr_col, ret_col]]\n",
    "        ret_orders = art_df[art_df[ret_col]>=1][ordnr_col]\n",
    "\n",
    "        basket_df = multi_arts[(multi_arts[ordnr_col].isin(art_df[ordnr_col])) &    # all articles which were ordered with article\n",
    "                      (multi_arts[artnr_col] != article)]\n",
    "        if drop_double_rets:   # ignores probability if both articles got returned\n",
    "            basket_df = basket_df.drop(basket_df[basket_df[ret_col]==1].index)\n",
    "        else:\n",
    "            basket_df.loc[:, ret_col] = 0   # set all ret_cols to 0\n",
    "        ret_incides = basket_df[basket_df[ordnr_col].isin(ret_orders)].index\n",
    "        basket_df.loc[ret_incides, ret_col] = 1 # set ret_col = 1 if returned\n",
    "        basket_grouped = basket_df.groupby(artnr_col).size()\n",
    "        \n",
    "        # for every min_joint_baseket combination\n",
    "        for n_arts in min_n_arts:\n",
    "            arts_basket_occ = basket_grouped[basket_grouped>=n_arts]   # only add arts with sufficient occurances\n",
    "            if arts_basket_occ.shape[0] > 0:\n",
    "                lookup_basket_occ[n_arts][article] = arts_basket_occ   # .to_dict() # minimum of co-occurances\n",
    "                lookup_basket_ret_p[n_arts][article] = basket_df[basket_df[artnr_col].isin(arts_basket_occ.keys())].groupby(\n",
    "                    artnr_col)[ret_col].mean()  #.to_dict()\n",
    "                lookup_lift_arts[n_arts][article] = arts_basket_occ.index.to_series().apply(lambda x: (arts_basket_occ.loc[x]/n_transactions)/\n",
    "                                      (lookup_rel_ord[article]*lookup_rel_ord[x]))\n",
    "            else:\n",
    "                lookup_droped_ret_arts[n_arts] += [article]\n",
    "    return [lookup_lift_arts, lookup_basket_occ, lookup_basket_ret_p, lookup_droped_ret_arts]\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMCFeatures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
